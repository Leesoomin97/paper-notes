# 2025-10-26_A survey on Multimodal Large Language Models-paper

## 1. 논문 내용 정리

#### (1) 연구 배경
해당 논문은 GPT-4V를 비롯한 Multimodal Large Language Models(MLLMs)가 언어 모델(LLM)의 추론 능력에 이미지, 영상, 음성 등 다양한 입력 모달리티를 통합하면서 AI 연구의 새로운 중심축으로 부상했음을 언급하며 시작한다.  

이는 단순히 '언어를 이해하는 모델'에서 '세상을 인식하고 설명하는 모델'로의 전환을 의미한다.  

논문은 MLLM의 기본 구조, 학습 절차, 평가 체계, 환각 문제, 확장 기법, 향후 과제를 종합적으로 분석한다.  

#### (2) 기본 구조
MLLM은 크게 세 구성 요소로 이루어진다.  

- **Modality Encoder** - 시각, 음성 등 비언어 데이터를 벡터로 변환한다.(CLIP, EVA-CLIP 등)  
- **Large Language Model(LLM)** - 언어적 추론을 수행한다.(LLaMA, Vicuna, Qwen 등)  
- **Connector** - 인코더와 LLM의 표현 공간을 정렬한다.(MLP Projection, Q-Former, Cross-Attention 등)  

예를 들어 LLaVA는 CLIP 인코더가 생성한 이미지 임베딩을 MLP Projection으로 연결하여 LLM이 이미지 내용을 이해하도록 한다.  

#### (3) 학습 단계
MLLM의 학습은 사전학습(Pre-training) → 지시 튜닝(Instruction-tuning) → 정렬 튜닝(Alignment-tuning) 순으로 이루어진다.  

- **사전학습**은 대규모 이미지, 텍스트 데이터 등으로 모달리티 간 의미 정렬을 학습하는 단계이다.  
- **지시 튜닝**은 'Describe the image.'와 같은 명령형 데이터를 통해 인간의 지시와 과제 수행 능력을 학습하는 단계이다.  
- **정렬 튜닝**은 RLHF나 DPO를 활용하여 인간의 가치, 사회적 맥락, 윤리 기준에 맞게 모델 출력을 조정하는 단계이다.  

즉, 정렬 튜닝은 AI가 '사실을 말하는 모델'에서 '사람이 신뢰할 수 있는 방식으로 말하는 모델'로 진화하게 만드는 핵심 과정이다.  

#### (4) 평가 체계
MLLM의 평가는 두 가지 방향으로 이루어진다.  

- **폐집합 과제(Closed-set):** VQA, Caption, OCR 등 명확한 정답이 있는 과제  
- **개방형 과제(Open-set):** 자유 응답형 대화, 창의적 질의응답 등  

최근에는 MME, POPE, AMBER 등 전용 벤치마크가 등장하면서 단순 정확도 외에도 언어적 유창성, 시각적 근거 활용, 추론 일관성이 함께 평가 지표로 사용된다.  

#### (5) 확장 및 응용
MLLM은 다양한 산업과 도메인으로 확장되고 있다.  

- **입출력 세분화(Gramularity):** 픽셀, 객체, 좌표 단위로 세밀한 제어 수행(Shikra, Ferret)  
- **모달리티 확장(Modality Expansion):** 오디오, 비디오, 3D 포인트 클라우드 통합(NExT-GPT, 3D-LLM)  
- **언어 확장(Multilinmuality):** 다국어 이해, 생성 능력 향상(Qwen-VL, visCPM)  
- **도메인 특화(Domain Adaptation):** 의료(LLaVA-Med), 문서(mPLUG-DocOwl), 산업(MobileVLM) 등  

#### (6) 멀티모달 환각(Multimodal Hallucination)
시각 정보와 언어 표현이 불일치할 때 MLLM은 환각(hallucination) 문제를 보인다. 존재하지 않는 객체를 언급하거나 속성을 잘못 기술하는 경우가 그 예이다.  

이를 해결하기 위한 접근법은 세 가지로 나뉜다.  

- **Pre-correction:** 부정 샘플을 통한 사전 보정(LLaVA-RLHF)  
- **In-process:** Attention 구조 개선 및 언어 편향 완화(HallE-Switch, VCD)  
- **Post-correction:** 외부 검증 모델로 후처리(Woodpecker, LURE)  

#### (7) 확장된 기법(Advanced Methods)
MLLM은 단순한 인식 단계를 넘어, 추론(reasoning) 능력을 확장하기 위해 다음과 같은 기법을 사용한다.  

| 기법 | 개념 | 특징 |
|:--|:--|:--|
| M-ICL | 예시 기반 Few-shot 학습 | 일반화 능력 향상 |
| M-CoT | 단계적 추론(Chain-of-Thought) | 복합 reasoning 가능 |
| LAVR | LLM 논리와 시각 근거 결합 | 시각적 추론 강화 |  

특히 LAVR은 모델이 '왜 그런 판단을 했는가'를 설명할 수 있도록 만드는 핵심 확장 방향이다.  

#### (8) 향후 과제
논문은 다음 네 가지를 MLLM의 향후 핵심 과제로 제시한다.  

1. 환각 최소화 및 신뢰성 확보  
2. 고품질 멀티모달 데이터 확보  
3. 다수의 모달 대화형 에이전트 발전  
4. 효율적 학습 및 경량화  

---

## 2. 기술적 논의 및 산업적 해석

#### (1) 정렬 튜닝(Alignment Tuning)의 중심성
MLLM의 학습 단계는 사전 학습, 지시 튜닝, 정렬 튜닝으로 구성되지만, 이 중에서 가장 주목해야 할 것은 정렬 튜닝이다.  
그 이유는 정렬 튜닝이 모델의 인간 중심 해석 능력(Human-centric Interpretation)을 결정하기 때문이다.  

사전학습이 지식을 축적하는 과정이라면, 정렬 튜닝은 그 지식을 인간의 감정, 언어적 관습, 윤리적 기준에 맞게 재정렬하는 과정이다.  
이 단계에서 AI는 단순히 정확히 답하는 것을 넘어 어떻게 답해야 인간이 신뢰할 수 있는가를 학습한다.  

이 때문에 각 기업은 서로 다른 정렬 접근 방식을 취하고 있다.  

- **Open AI:** RLHF + RLAIF를 통해 인간 및 AI 피드백 병합 정렬  
- **Anthropic:** Constitutional AI를 통해 윤리적 규칙(rule set) 내재화  
- **Google DeepMind:** AI 스스로 평가, 보정하는 RLAIF 구조 강화  
- **X(AI):** 현실 기반 정렬(Realistic Alignment), SNS 언어를 활용한 감정적 학습  

즉, 정렬은 모델 경쟁의 중심축이자, 인간화된 인공지능으로 가는 통로이다.  

#### (2) 순환형 보강 구조(Interative Reinforcement Loop)
최근 MLLM은 선형적 학습 구조에서 벗어나 정렬 → 지시 튜닝 → 사전학습이 상호 피드백을 이루는 순환 구조로 발전하고 있다.  

이 구조에서는  
- 정렬 결과가 새로운 지시 데이터로 재활용되고,  
- 지시 튜닝 결과가 다시 사전학습의 질을 향상시키며,  
- 전체 시스템이 '자기 보정(self-reinforcing)' 형태로 진화한다.  

즉, 정렬 품질은 단일 학습 단계의 문제가 아니라 지속적으로 순환 강화되는 학습 루프의 중심 변수이다.  

#### (3) 차세대 경쟁 축: 세분화(Granularity)와 도메인 적응력(Domain Adaptation)
AI 산업이 앞으로 세분화와 도메인 적응력에 집중해야 하는 이유는 명확하다. 이 두 요소가 AI의 정확도, 신뢰성, 응용 확장성을 동시에 결정하기 때문이다.  

- **세분화**는 모델이 객체, 좌표, 픽셀 단위로 세밀한 reasoning을 수행할 수 있는 능력이다. 이는 자율주행, 의료 영상 분석, UI 해석 등 실제 환경에서의 정밀 제어를 가능하게 한다.  
- **도메인 적응력**은 특정 산업에서 전문가 수준의 정합성과 맥락 이해를 구현하기 위한 기술이다. 이는 단순한 데이터 학습이 아니라, 도메인의 규칙, 언어, 추론 구조를 모델 내부에 내재화하는 과정을 의미한다.  

결국 AI 시장의 승자는 더 큰 모델을 가진 기업이 아니라 더 잘 정렬되고, 더 세밀하며, 특정 도메인에 특화된 모델을 만든 기업이 될 것이다.  

---

## 3. 결론 및 시사점
AI 발전의 핵심은 이제 정렬, 세분화, 도메인 적응력의 삼중 결합이다. 이 세 가지는 모델의 크기보다 더 근본적으로 AI가 사회적 맥락, 인간 언어, 산업 환경에 적응할 수 있는지를 결정한다.  

현재는 AI 시장은 과도기를 겪고 있다. 이에 따라 연구자와 기업은 모두,  

1. 정렬 품질과 피드백 투명성을 높이고,  
2. 세분화된 입력, 출력 제어 기술을 강화하며,  
3. 도메인 특화형 데이터 루프를 구축해야 한다.  

AI의 진보는 이제 얼마나 많이 배웠는가를 넘어 '얼마나 인간과 맥락적으로 대화할 수 있는가'로 평가될 것이다.  

---

## 4. 출처
Shukang Yin et al. (2024.09). A Survey on Multimodal Large Language Models. arXiv:2306.13549  
https://arxiv.org/abs/2306.13549
