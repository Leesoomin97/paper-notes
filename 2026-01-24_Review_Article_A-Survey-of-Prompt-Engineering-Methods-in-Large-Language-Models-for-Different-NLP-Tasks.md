# 1. Abstract

## 1.1 배경 및 기술의 부상

- **LLM의 발전**: 대규모 언어 모델이 다양한 NLP 태스크에서 유례없는 성과를 보이며 인공지능 분야의 핵심으로 자리 잡음.
- **프롬프트 엔지니어링의 역할**: 모델 내부에 내재된 방대한 지식을 **자연어 지침(Prompt)**을 통해 체계적으로 추출하는 핵심 기술로 부상함.

## 1.2 기술적 특징 및 차별점

- **효율성**: 기존 방식과 달리 모델의 파라미터를 수정하는 재학습이나 미세 조정(Fine-tuning) 과정이 불필요함.
- **접근성**: 깊은 수학적·이론적 머신러닝 배경 없이도 자연어 대화만으로 모델 활용 및 실험이 가능함.
- **정확도 향상**: 최근 2년간 정확한 정보 추출을 위해 다양하고 정교한 프롬프트 설계 기법들이 제안됨.

## 1.3 본 논문의 연구 범위 및 기여

- **체계적 분류**: 지난 2년간 발표된 44편의 핵심 논문을 분석하여 39가지 프롬프트 기법을 도출함.
- **태스크 중심 분석**: 도출된 기법들을 29개의 NLP 태스크별로 분류하고 분류도(Taxonomy Diagram)를 통해 구조화함.
- **성능 지표 제시**: 각 데이터셋에 대해 보고된 잠재적 최고 성능(SoTA) 프롬프팅 방법론을 논의함.

---

# 2. Introduction

## 2.1 연구의 배경 및 프롬프트 엔지니어링의 부상 

- **LLM의 진화**: LLM은 방대한 데이터와 파라미터 증가를 통해 의학, 법률, 금융 등 다양한 산업에서 뛰어난 성능을 보여주고 있음.
- **패러다임의 전환**: 연구의 초점이 단순한 '다음 토큰 예측'에서 프롬프트를 통한 '추론 능력'으로 이동하며 프롬프트 엔지니어링이라는 새로운 분야가 탄생함.
- **핵심 장점**: 전통적인 모델과 달리 광범위한 파라미터 재훈련이나 미세 조정(Fine-tuning) 없이 모델 내부에 내재된 지식만을 활용하여 효율적으로 결과를 도출함.
- **접근성**: 전문적인 수학적 배경이 없어도 자연어 대화를 통해 AI로부터 필요한 정보를 체계적으로 추출할 수 있음

## 2.2 본 논문의 차별성과 기여점

- **광범위한 분석 범위**: 특정 하위 분야(e.g. 개인정보 보호)에 집중하거나 적은 수의 방법론(9~10개)만 다루었던 기존 서베이들과 차별화하여, 총 44개의 연구 논문에서 추출한 39가지 기법을 29개의 작업에 적용해 분석함.
- **세밀한 분류(Granular Categorization)**: 기존 연구들이 '추론과 논리'처럼 광범위한 범주로 기법을 묶었던 것과 달리, 본 논문은 상식 추론, 수학적 문제 해결, 멀티홉 추론 등 구체적인 NLP 작업(Task)별로 세분화하여 분석함.

---

# 3. Prompt Engineering Techniques  

## 3.1 추론 및 논리 강화 기법 (Reasoning & Logic Foundations)

| 번호 | 기법 명칭 | 핵심 아이디어 | 방법 | 주요 적용 분야 | 개선된 점 |
|----|-----------|---------------|------|----------------|-----------|
| 2.1 | Basic (Vanilla) Prompting | 별도의 엔지니어링 없이 직접 질문을 던지는 가장 기본적인 방식 | 모델에 질문(Query)을 직접 입력함 | 모든 NLP 작업 | 모든 전략의 기초이자 성능 비교의 기준점이 됨 |
| 2.2 | Chain-of-Thought (CoT) | 인간이 복잡한 문제를 작은 단위로 나누어 해결하는 과정에서 착안 | 중간 추론 단계(중간 단계 시퀀스)를 순차적으로 생성하도록 함 | 수학적 문제 해결, 상식 추론 | 수학 문제 해결에서 Basic 대비 최대 약 39%의 성능 향상 |
| 2.3 | Self-Consistency | 복잡한 추론 문제일수록 여러 가지 정답 경로가 존재할 수 있다는 직관 | 1. CoT로 질문함<br>2. 다양한 추론 경로를 샘플링함<br>3. 가장 일관된 정답을 최종 선택함 | 수학 문제 해결, 상식/멀티홉 추론 | CoT와 비교해 수학 문제 11%, 멀티홉 추론 6% 성능 추가 향상 |
| 2.5 | Automatic CoT (Auto-CoT) | 수동 CoT에 필요한 고품질 예시 제작의 번거로움을 해결하고자 함 | 1. 질문들을 클러스터링함<br>2. 클러스터별 대표 질문을 뽑음<br>3. Zero-shot CoT로 추론 체인을 자동 생성함 | 수학 문제 해결, 멀티홉/상식 추론 | 수동으로 제작된 CoT의 성능과 대등하거나 이를 능가함 |
| 2.6 | Complex CoT | 더 복잡한 추론 단계(예시)를 보여주는 것이 성능 향상에 유리하다는 가설 | 1. 추론 단계가 많은 복잡한 데이터를 예시로 사용함<br>2. 결과 중 상위 K개 복잡한 체인에서 다수결로 답을 도출함 | 수학 문제 해결, 상식/멀티홉 추론 | 수학 및 상식 추론 등에서 평균 5.3%의 정확도 향상 달성 |
| 2.8 | Least-to-Most | CoT가 예시보다 어려운 난이도의 문제를 만났을 때 실패하는 점을 보완함 | 1. 문제를 하위 문제들로 분해함<br>2. 하위 문제들을 순차적으로 해결하며 그 결과를 다음 단계에 활용함 | 상식/언어 기반 작업, 수학적 문제 해결 | CoT 및 Basic 방식보다 훨씬 뛰어난 성능을 보임 |
| 2.11 | Plan-and-Solve (PS) | CoT의 계산 오류, 단계 누락, 의미 오해 문제를 해결하고자 함 | 1. 전체 문제를 하위 문제로 나누는 계획을 수립함<br>2. 계획에 따라 하위 문제들을 실행함 | 수학적 문제 해결, 상식/멀티홉 추론 | 제로샷(Zero-shot) 설정에서 CoT보다 최소 5% 이상 정확도 개선 |

---

## 3.2 프로그래밍 및 기호 활용 기법 (Computational & Structured Approach)

추론 과정에 외부 인터프리터(Python 등)를 도입하거나 코드 구조를 활용해 수치 계산의 정확도를 높이는 그룹

| 번호 | 기법 명칭 | 핵심 아이디어 | 방법 | 주요 적용 분야 | 개선된 점 |
|----|-----------|---------------|------|----------------|-----------|
| 2.7 | Program-of-Thoughts (PoT) | LLM이 추론과 계산을 모두 하면 오류가 생기기 쉬우므로, 계산은 파이썬에 맡김 | 추론 과정은 LLM이 하되, 계산 부분은 Python 프로그램으로 생성하여 외부 인터프리터에서 실행함 | 수학적 문제 해결, 문맥 질문 답변 | CoT 대비 평균 약 12%의 성능 향상을 보이며 수치 추론 정확도가 높아짐 |
| 2.9 | Chain-of-Symbol (CoS) | 자연어는 공간적 묘사를 하기에 복잡하고 중복된 정보가 섞일 수 있다는 가설 | 공간적 관계를 설명할 때 자연어 대신 단어 시퀀스 내의 '기호'를 사용해 표현함 | 공간 질문 답변 (Spatial QA) | 공간 질문 답변 작업에서 정확도를 최대 60.8%까지 개선함 |
| 2.10 | Structured Chain-of-Thought (SCOT) | 프로그래밍의 제어 구조(조건문, 반복문 등)가 인간 개발자의 사고방식과 유사하다는 점에 착안 | 순차(sequencing), 분기(branching), 반복(looping) 같은 프로그램 구조를 사용해 중간 추론 단계를 구조화함 | 코드 생성 (Code Generation) | 코드 생성 작업에서 기존 CoT 대비 성능을 최대 13.79% 향상시킴 |
| 2.29 | Chain-of-Code (CoC) | 실행 불가능한 의미론적 코드도 LLM이 시뮬레이션하면 코드 중심의 추론이 강화됨 | 코드를 작성한 뒤 실제 실행 가능한 부분은 인터프리터가, 불가능한 부분은 LLM이 직접 시뮬레이션(LMulator)함 | 추천 시스템, 인과 추론, 상식 추론 등 | 추론 정확도를 높여 다양한 벤치마크에서 기존 베이스라인을 능가함 |
| 2.30 | Program-Aided Language Models (PAL) | 자연어 추론과 프로그래밍 문장을 섞어 쓰는 것이 복잡한 논리 해결에 유리함 | 자연어 문제 읽기와 프로그래밍 문장이 교차된 형태의 추론 단계를 생성하고 실행함 | 수학적 문제 해결, 상식 추론 등 | CoT나 기본 방식보다 우수한 성능을 보여줌 |

---
## 3.3 앙상블 및 자가 검증 기법 (Ensemble & Self-Verification)

여러 개의 답을 만들어 비교하거나, AI가 자신의 답을 스스로 검토하여 할루시네이션(환각)을 줄이는 그룹

| 번호 | 기법 명칭 | 핵심 아이디어 | 방법 | 주요 적용 분야 | 개선된 점 |
|----|-----------|---------------|------|----------------|-----------|
| 2.4 | Ensemble Refinement (ER) | CoT와 Self-Consistency의 아이디어를 결합하여 더 나은 설명을 생성함 | 1. 온도를 조절해 여러 추론 답변 생성<br>2. 생성된 답변들을 다시 입력값으로 넣어 더 나은 최종 답변 도출 | 문맥 없는 질문 답변 (Context-Free QA) | 여러 데이터셋에서 CoT 및 Self-Consistency보다 우수한 성능 기록 |
| 2.17 | Tree-of-Thoughts (ToT) | 문제 해결 공간을 '나무(Tree)' 구조로 탐색하며 각 경로를 평가함 | 각 생각의 조각을 노드로 삼아 너비/깊이 우선 탐색을 수행하고, 모델이 직접 각 경로의 유망성을 평가함 | 수학 문제, 논리 추론, 창의적 글쓰기 | 수학 문제에서 CoT보다 65% 더 높은 성공률을 기록함 |
| 2.20 | Verify-and-Edit (VE) | CoT로 생성된 답변이 사실과 맞지 않는 경우를 사후에 수정함 | 1. 결과가 불확실한지 판단<br>2. 외부 지식에서 사실 관계를 검색<br>3. 이를 바탕으로 답변을 다시 편집함 | 멀티홉 추론, 진실성 작업 | 멀티홉 추론 작업에서 기존 방식 대비 정확도를 최대 10% 향상시킴 |
| 2.27 | Chain-of-Verification (CoVe) | 모델이 스스로 질문을 만들어 자신의 답변 오류를 검증함 | 1. 기본 답변 생성<br>2. 검증 질문 생성<br>3. 질문에 답하며 오류 확인<br>4. 최종 수정본 작성 | 질문 답변, 자유 응답 | 사실 관계 오류를 줄여 기존 방식보다 최소 10% 이상 우수한 성능을 보임 |
| 2.36 | Metacognitive Prompting (MP) | 인간의 자기 성찰(메타인지) 과정을 모방하여 답변의 신뢰도를 평가함 | 이해 → 판단 → 비판적 평가 → 최종 결정 → 신뢰도 측정의 5단계를 거침 | 패러프레이징, 개체명 인식, 관계 추출 등 | 여러 NLP 작업에서 CoT와 Plan-and-Solve를 일관되게 능가함 |

---

## 3.4 지식 검색 및 데이터 구조화 기법 (Knowledge Retrieval & Data Structuring)

외부 지식을 가져오거나, 표(Table)와 같은 정형 데이터를 효율적으로 처리하기 위해 고안된 그룹

| 번호 | 기법 명칭 | 핵심 아이디어 | 방법 | 주요 적용 분야 | 개선된 점 |
|----|-----------|---------------|------|----------------|-----------|
| 2.24 | Implicit Retrieval Augmented Generation (Implicit RAG) | 외부 DB 대신 모델 스스로 지식의 핵심 구간을 추출한 뒤 답하게 함 | 모델에게 주어진 문맥에서 중요한 섹션들을 먼저 추출하게 하고, 그 정보를 바탕으로 질문에 답함 | 문맥 기반 질문 답변 (Contextual QA) | 환자 케이스 보고서 등 의학 분야 데이터셋에서 최고 성능(SoTA)을 달성함 |
| 2.28 | Chain-of-Knowledge (CoK) | 지식 도메인을 식별하고 답변의 합의가 없을 때 지식을 적응시켜 할루시네이션을 방지함 | 1. 예비 근거 준비 및 지식 도메인 확인<br>2. 다수결 합의가 없으면 단계별로 지식 수정<br>3. 수정된 근거로 답변 통합 | 멀티홉 추론, 진실성, 표 기반 QA | CoT, Self-Consistency 등 기존 방식 대비 여러 작업에서 최소 1~3% 이상 성능 향상 |
| 2.31 | Binder | 언어 모델의 기능과 SQL/Python 같은 프로그래밍 언어를 결합해 문법 범위를 넓힘 | 1. 입력을 프로그램(SQL 등)으로 매핑<br>2. 인터프리터로 실행하여 결과 반환 (훈련이 필요 없는 방식) | 표 기반 진실성 및 QA | 명시적인 미세 조정 없이도 표 기반 추론 작업에서 우수한 정확도를 기록함 |
| 2.32 | Dater | 거대한 표와 복잡한 쿼리를 작게 분해하여 효율적으로 추론함 | 1. 표를 관련 하위 표로 분해<br>2. 자연어 질문을 SQL 형태의 하위 쿼리로 분해<br>3. 이를 조합해 최종 답 도출 | 표 기반 추론, 표 기반 QA | 표 기반 진실성 작업에서 기존 미세 조정 모델보다 최소 2% 이상 뛰어난 성능을 보임 |
| 2.33 | Chain-of-Table | CoT의 아이디어를 표 형식에 맞춰 확장하여 표 이해도를 높임 | 1. 다음 표 작업(열 추가, 행 정렬 등) 계획<br>2. 작업 인자 생성 및 표 변환<br>3. 최종 변환된 표로 질문 답변 | 표 기반 QA 및 진실성 | 표 기반 QA 및 진실성 작업에서 기존 기록들을 깨고 최고 성능(SoTA)을 기록함 |
| 2.38 | Basic with Term Definitions | 의학 용어 정의를 추가하면 모델이 더 정확한 문맥을 파악할 것이라는 가설 | 기본 프롬프트 지침에 관련 의학 용어의 정의를 추가하여 입력함 | 의학 분야 질문 답변 | 결과적으로는 고정된 정의가 모델의 기존 지식과 충돌하여 오히려 혼란을 줄 수 있음이 밝혀짐 |
| 2.39 | Basic + Annotation Guideline + Error Analysis Prompting | 가이드라인과 과거 오류 분석 내용을 제공해 작업의 정확도를 높임 | 개체 정의, 언어 규칙, 이전 출력의 오류 분석 결과를 프롬프트에 포함함 | 임상 개체명 인식 (NER) | 여러 NER 데이터셋에서 평균 0.57의 F1 점수를 기록하며 효과를 증명함 |

---
## 3.5 데이터 증강 및 예시 강화 기법 (Data Augmentation & Exemplar Enhancement)

모델에게 더 나은 예시를 제공하거나, 모델 스스로 예시를 만들게 하여 학습 효과를 극대화하는 그룹

| 번호 | 기법 명칭 | 핵심 아이디어 | 방법 | 주요 적용 분야 | 개선된 점 |
|----|-----------|---------------|------|----------------|-----------|
| 2.13 | Contrastive CoT / Contrastive Self-Consistency | 인간이 긍정적 예시와 부정적 예시를 모두 보며 배우는 방식에서 착안 | 정답인 추론 과정(Positive)과 오답인 추론 과정(Negative)을 동시에 예시로 제공함 | 수학적 문제 해결, 멀티홉 추론 | 수학 문제에서 기존 CoT 대비 평균 10%, 멀티홉 추론에서 10% 이상 성능이 향상됨 |
| 2.15 | Analogical Reasoning | 새로운 문제를 풀 때 과거의 유사한 경험을 떠올리는 심리학적 개념 활용 | 모델에게 원본 문제와 유사한 예시들을 스스로 생성하고 먼저 풀게 한 뒤, 실제 문제를 풀게 함 | 수학, 코드 생성, 논리 추론 등 | CoT 대비 평균 4%의 정확도 향상을 보이며 다양한 논리 작업에서 효과를 입증함 |
| 2.16 | Synthetic Prompting | 사람이 직접 예시를 만드는 번거로움을 줄이기 위해 모델이 스스로 예시를 증강함 | 1. 추론 체인 기반 쿼리 생성<br>2. 생성된 쿼리에 대한 추론 체인 생성으로 정확도 검증 | 수학, 상식, 논리 추론 | 수학 및 논리 작업 데이터셋에서 최대 15.6%의 절대적인 성능 이득을 얻음 |
| 2.22 | Active-Prompt | 특정 작업에 가장 적합하고 중요한 질문들을 선별해 예시로 활용함 | 1. 질문들에 대해 여러 답 생성<br>2. 불확실성 측정 후 가장 불확실한 질문 선별<br>3. 선별된 질문을 인간이 검수해 예시로 사용 | 수학, 상식, 멀티홉 추론 | Self-Consistency, CoT 등 기존 기법들을 여러 데이터셋에서 능가하는 결과를 보여줌 |

---

## 3.6 복합 추론 및 맥락 최적화 기법 (Complex Reasoning & Context Optimization)

모델의 주의 집중력을 높이거나, 복합적인 행동 단계를 설계하여 고도의 문제 해결 능력을 끌어내는 그룹

| 번호 | 기법 명칭 | 핵심 아이디어 | 방법 | 주요 적용 분야 | 개선된 점 |
|----|-----------|---------------|------|----------------|-----------|
| 2.12 | MathPrompter | 수학 문제 해결 시 단계의 타당성을 검증하고 결과의 신뢰도를 측정함 | 1. 변수를 포함한 대수식 생성<br>2. 파이썬 함수 등으로 분석적 해결<br>3. 무작위 값을 대입해 검증<br>4. 다수결로 최종 답 산출 | 수학적 문제 해결 | 특정 데이터셋에서 정확도를 78.7%에서 92.5%로 대폭 향상 |
| 2.14 | Fed-SP/DP-SC/CoT | 크라우드 소싱된 유사 질문들을 활용해 모델의 추론 능력을 강화함 | 동일 파라미터를 가진 질문을 재해석(Fed-SP-SC)하거나, 여러 질문의 답변을 연합하여 힌트로 제공(Fed-DP-CoT)함 | 수학적 문제 해결 | 기존 CoT 방식보다 최소 10%에서 최대 20%의 성능 향상을 보임 |
| 2.18 | Logical Thoughts (LoT) | '귀류법(Reductio ad Absurdum)'과 논리적 동치 원리를 사용해 제로샷 추론을 개선함 | 단계별로 추론한 뒤, 논리적 가이드라인에 따라 이를 검증하고 필요 시 수정하여 유효한 결론에 도달함 | 수학, 상식, 논리, 인과, 사회적 추론 | 상식 추론에서 최대 16.2%, 사회적 추론에서 10%의 정확도 향상을 기록함 |
| 2.19 | Maieutic Prompting | 재귀적 추론을 통해 모순되는 대안들을 제거하고 일관된 응답을 유도함 | 명제들 간의 논리적 연결을 트리 구조로 생성하고, 각 명제에 대한 모델의 믿음을 측정하여 최종 답을 추론함 | 상식 추론 | 상식 추론 작업에서 기본 방식이나 CoT 대비 최대 20% 더 높은 정확도 달성 |
| 2.21 | Reason + Act (ReAct) | 추론(생각)과 행동(외부 도구 사용 등)을 결합하여 복잡한 결정을 내림 | 언어적인 추론 과정(Traces)과 그에 따른 실제 행동(Actions)을 번갈아 가며 수행함 | 멀티홉 추론, 진실성, 작업 완료 | 언어 기반 작업 완료 분야에서 강화 학습 방식보다 10% 이상의 성공률 개선 |
| 2.23 | Thread-of-Thought (ThoT) | 방대하고 혼란스러운 문맥 속에서도 사고의 흐름을 끊기지 않게 유지함 | 1. 문맥의 각 섹션을 분석하고 요약함<br>2. 요약된 정보를 바탕으로 최종 질문에 답함 | 문맥 없는 질문 답변, 대화 시스템 | 대화 시스템 작업에서 기존 기법들을 제치고 가장 높은 점수(3.8)를 기록함 |
| 2.25 | System 2 Attention (S2A) | 판단을 방해하는 불필요하거나 편향된 정보에 휘둘리지 않게 함 | 1. 주어진 문맥에서 불필요한 부분을 제거하고 재생성함<br>2. 정제된 문맥만을 사용하여 최종 답변을 생성함 | 진실성 (Truthfulness) | 진실성 관련 데이터셋에서 기본 방식 및 CoT보다 우수한 성능을 보임 |
| 2.26 | Instructed Prompting | 모델에게 무관한 정보를 무시하라고 명시적으로 지시 | 문제 설명에 포함된 불필요한 정보나 노이즈를 무시하라는 지침을 프롬프트에 직접 포함함 | 진실성 (Truthfulness) | 진실성 작업에서 88.2의 정규화 정확도를 기록하며 여러 경쟁 기법을 능가함 |
| 2.34 | Decomposed Prompting (DecomP) | 복잡한 문제를 하위 문제별로 특화된 모델들에게 할당하여 해결함 | 계층적 또는 재귀적 방식으로 문제를 나누고, 외부 API를 호출하거나 전문 모델을 사용해 처리함 | 상식 추론, 멀티홉 추론 | 상식 추론에서 CoT 및 Least-to-Most 방식보다 평균 25% 더 우수한 결과 기록 |
| 2.35 | Three-Hop Reasoning (THOR) | 인간의 감정 이해 프로세스를 모방해 감성 분석의 정확도를 높임 | 1. 대상 파악<br>2. 세부 의견 분석<br>3. 최종 감정 극성(긍정/부정) 판정의 3단계 수행 | 감정/감성 이해 | 여러 감성 분석 데이터셋에서 기존의 최고 성능(SoTA) 기록을 유의미하게 경신함 |
| 2.37 | Chain-of-Event (CoE) | 사건의 흐름을 파악하여 더 논리적이고 간결한 요약을 생성함 | 1. 사건 추출<br>2. 일반화 및 정제<br>3. 핵심 사건 필터링<br>4. 시간 순서로 통합 | 요약 (Summarization) | 요약 데이터셋에서 CoT보다 높은 ROUGE 점수를 기록하며 더 간결한 결과물을 도출함 |

---

# 4. Prompt Engineering on Different NLP Tasks

## 4.1 데이터셋 분류 원칙

- **분류 기준의 다양성**: 연구마다 데이터셋을 NLP 작업으로 분류하는 측정 기준이 상이함.
- **단일 작업 매핑**: 하나의 데이터셋이 여러 작업에 속할 수 있으나, 가장 강하게 연관된 단 하나의 작업으로만 분류함.

## 4.2 SoTA(최고 성능) 표기 방식

- **기법 명칭 위주**: 특정 LLM과 실험되지 않은 기법들이 많아 불확실성이 존재하므로, 모델명이 아닌 프롬프팅 기법의 이름만 언급함.
- **평가 지표 생략**: 작업마다 사용되는 평가 지표가 달라 일관성을 유지하기 위해 지표를 별도로 나열하지 않음.
- **분석적 판단**: 데이터셋의 파편화된 실험 결과들을 종합하여 저자들의 이해와 최선의 판단을 바탕으로 SoTA를 선정함.

---

# 5. Q&A

**Q:** 프롬프팅의 복잡함이 LLM의 성능을 향상하는가? vs 프롬프팅의 예시가 LLM 성능을 향상하는가?

## A

### ① Self-Consistency의 핵심 원리
Self-Consistency는 "프롬프트가 복잡해질수록 모델이 어려워한다"는 개념이 아니라, 복잡한 추론 문제일수록 정답에 도달하는 경로가 여러 개 존재한다는 직관에 기반한다.

### ② 작동 방식
Self-Consistency는 단일 greedy decoding 대신 여러 개의 다양한 추론 경로를 샘플링하고, 가장 일관되게 나타나는 답변을 최종 답으로 선택하는 디코딩 전략이다. 같은 문제를 여러 번 풀어보고 가장 많이 나온 답을 다수결 투표로 채택하는 방식으로, 단일 추론 경로의 오류를 보완한다.

### ③ 왜 효과적인가
복잡한 문제는 여러 해결 방법이 있지만 올바른 답은 하나이다. 예를 들어 수학 문제를 풀 때 방정식으로 접근할 수도 있고, 단계적 계산으로 접근할 수도 있지만 정답은 동일합니다. Self-Consistency는 이러한 다양한 경로를 모두 탐색하여 일관된 답을 찾아낸다.

### ④ 긴 프롬프트의 문제점

- **주의 분산**: 모델의 집중력이 과도한 세부사항에 흩어져 핵심 요구사항을 놓칠 수 있다
- **최신성 편향 (Recency Bias)**: Transformer는 최근 토큰에 더 높은 가중치를 부여하여, 프롬프트 초반의 중요한 정보를 무시할 수 있다
- **환각 증가**: 128K 토큰 프롬프트보다 16K 토큰 프롬프트가 정확도와 관련성에서 더 우수한 결과를 보였다

### ⑤ 프롬프트 복잡도와 모델 성능
실험 결과에 따르면, 지시사항의 복잡도가 증가하면 특히 PaLM2와 Falcon-7B 같은 모델에서 준수도가 떨어진다. 간단한 과제(예: 감성 분류)는 간결한 프롬프트로도 성능이 유지되거나 향상되지만, 민감하고 세밀한 과제(예: 혐오표현 탐지)에서는 간결한 프롬프트가 정확도 하락으로 이어진다.

### ⑥ Self-Consistency와의 차이
Self-Consistency는 "프롬프트를 복잡하게 만드는 것"이 아니라, "동일한 복잡한 문제를 여러 방식으로 풀게 하는 것"이다. 문제 자체는 복잡하지만, 각 추론 경로마다 프롬프트는 명확하고 구조화되어 있다. Chain-of-Thought처럼 단계적 추론을 유도하는 것이 핵심이며, 불필요하게 긴 설명을 추가하는 것이 아니다.

---
Reference: https://arxiv.org/abs/2407.12994